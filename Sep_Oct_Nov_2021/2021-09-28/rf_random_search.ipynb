{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-precess data to get the merged one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process the dataset\n",
    "input_path='/pod/2/li-lab/Ziwei/Nanopore/daily/test/'\n",
    "df_T4=pd.read_csv(os.path.join(input_path, 'T4.bed'), sep='\\t')\n",
    "df_lambda=pd.read_csv(os.path.join(input_path, 'lambda.bed'), sep='\\t')\n",
    "df_5mClambda=pd.read_csv(os.path.join(input_path, 'lambda_5mC.bed'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>read_id</th>\n",
       "      <th>strand</th>\n",
       "      <th>5hmC_prob</th>\n",
       "      <th>5mC_prob</th>\n",
       "      <th>5C_prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>204</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.435397</td>\n",
       "      <td>0.085058</td>\n",
       "      <td>0.479545</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>261</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.342189</td>\n",
       "      <td>0.500821</td>\n",
       "      <td>0.156990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>261</td>\n",
       "      <td>fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.577034</td>\n",
       "      <td>0.057676</td>\n",
       "      <td>0.365290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>266</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.065316</td>\n",
       "      <td>0.861569</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>266</td>\n",
       "      <td>fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.794235</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.176880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb826a6c-c88b-45ac-9984-8b9d6bfb2f11</td>\n",
       "      <td>-</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.932103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb91267a-6661-4248-a084-554f231398c1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.964888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb9cee29-89d0-4a68-a4b4-8fe5c000289f</td>\n",
       "      <td>-</td>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.960363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bbee6b4a-acac-4db9-bbb8-2f379918b146</td>\n",
       "      <td>-</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.961085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bc26e861-9931-48fb-b4cb-2adc9ccbd2c0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.955738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            chr  start                               read_id strand  \\\n",
       "0    KJ477685.1    204  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "1    KJ477685.1    261  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "2    KJ477685.1    261  fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9      -   \n",
       "3    KJ477685.1    266  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "4    KJ477685.1    266  fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9      -   \n",
       "..          ...    ...                                   ...    ...   \n",
       "994    J02459.1     60  bb826a6c-c88b-45ac-9984-8b9d6bfb2f11      -   \n",
       "995    J02459.1     60  bb91267a-6661-4248-a084-554f231398c1      -   \n",
       "996    J02459.1     60  bb9cee29-89d0-4a68-a4b4-8fe5c000289f      -   \n",
       "997    J02459.1     60  bbee6b4a-acac-4db9-bbb8-2f379918b146      -   \n",
       "998    J02459.1     60  bc26e861-9931-48fb-b4cb-2adc9ccbd2c0      -   \n",
       "\n",
       "     5hmC_prob  5mC_prob   5C_prob  label  \n",
       "0     0.435397  0.085058  0.479545      2  \n",
       "1     0.342189  0.500821  0.156990      2  \n",
       "2     0.577034  0.057676  0.365290      2  \n",
       "3     0.065316  0.861569  0.073115      2  \n",
       "4     0.794235  0.028885  0.176880      2  \n",
       "..         ...       ...       ...    ...  \n",
       "994   0.054875  0.013023  0.932103      0  \n",
       "995   0.030720  0.004392  0.964888      0  \n",
       "996   0.032703  0.006934  0.960363      0  \n",
       "997   0.035734  0.003182  0.961085      0  \n",
       "998   0.040249  0.004014  0.955738      0  \n",
       "\n",
       "[2497 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the label column\n",
    "df_T4['label'] = '5hmC'\n",
    "df_lambda['label'] = '5C'\n",
    "df_5mClambda['label'] = '5mC'\n",
    "\n",
    "# Merge the dataset \n",
    "df = pd.concat([df_T4, df_5mClambda, df_lambda])\n",
    "\n",
    "# Create label column\n",
    "# Createa a label with representations: 5C = 0, 5mC = 1, 5hmC = 2\n",
    "df['label'] = df['label'].map({'5C':0, '5mC':1, '5hmC':2 })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    999\n",
       "0    999\n",
       "2    499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(input_path, 'total.test.bed'), sep='\\t', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loading!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>read_id</th>\n",
       "      <th>strand</th>\n",
       "      <th>5hmC_prob</th>\n",
       "      <th>5mC_prob</th>\n",
       "      <th>5C_prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>204</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.435397</td>\n",
       "      <td>0.085058</td>\n",
       "      <td>0.479545</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>261</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.342189</td>\n",
       "      <td>0.500821</td>\n",
       "      <td>0.156990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>261</td>\n",
       "      <td>fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.577034</td>\n",
       "      <td>0.057676</td>\n",
       "      <td>0.365290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>266</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.065316</td>\n",
       "      <td>0.861569</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>266</td>\n",
       "      <td>fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.794235</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.176880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb826a6c-c88b-45ac-9984-8b9d6bfb2f11</td>\n",
       "      <td>-</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.932103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb91267a-6661-4248-a084-554f231398c1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.964888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb9cee29-89d0-4a68-a4b4-8fe5c000289f</td>\n",
       "      <td>-</td>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.960363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bbee6b4a-acac-4db9-bbb8-2f379918b146</td>\n",
       "      <td>-</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.961085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bc26e861-9931-48fb-b4cb-2adc9ccbd2c0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.955738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             chr  start                               read_id strand  \\\n",
       "0     KJ477685.1    204  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "1     KJ477685.1    261  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "2     KJ477685.1    261  fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9      -   \n",
       "3     KJ477685.1    266  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "4     KJ477685.1    266  fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9      -   \n",
       "...          ...    ...                                   ...    ...   \n",
       "2492    J02459.1     60  bb826a6c-c88b-45ac-9984-8b9d6bfb2f11      -   \n",
       "2493    J02459.1     60  bb91267a-6661-4248-a084-554f231398c1      -   \n",
       "2494    J02459.1     60  bb9cee29-89d0-4a68-a4b4-8fe5c000289f      -   \n",
       "2495    J02459.1     60  bbee6b4a-acac-4db9-bbb8-2f379918b146      -   \n",
       "2496    J02459.1     60  bc26e861-9931-48fb-b4cb-2adc9ccbd2c0      -   \n",
       "\n",
       "      5hmC_prob  5mC_prob   5C_prob  label  \n",
       "0      0.435397  0.085058  0.479545      2  \n",
       "1      0.342189  0.500821  0.156990      2  \n",
       "2      0.577034  0.057676  0.365290      2  \n",
       "3      0.065316  0.861569  0.073115      2  \n",
       "4      0.794235  0.028885  0.176880      2  \n",
       "...         ...       ...       ...    ...  \n",
       "2492   0.054875  0.013023  0.932103      0  \n",
       "2493   0.030720  0.004392  0.964888      0  \n",
       "2494   0.032703  0.006934  0.960363      0  \n",
       "2495   0.035734  0.003182  0.961085      0  \n",
       "2496   0.040249  0.004014  0.955738      0  \n",
       "\n",
       "[2497 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=pd.read_csv(os.path.join(input_path, 'total.Megalodon.per_read.prob.bed.gz'),compression='gzip', sep='\\t')\n",
    "df=pd.read_csv(os.path.join(input_path, 'total.test.bed'), sep='\\t')\n",
    "print(\"Data is loading!\")\n",
    "\n",
    "#Splitting the data into independent and dependent variables\n",
    "df_feature = df.loc[:,['5hmC_prob','5mC_prob','5C_prob']].values\n",
    "df_class = df.loc[:,['label']].values\n",
    "df_class = np.squeeze(df_class) #Convert the label into 1d-array\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting is done!\n",
      "Current Time = 11:17:07, 09/29/21\n",
      "Before SMOTE: Counter({1: 799, 0: 799, 2: 399})\n",
      "After SMOTE: Counter({1: 799, 0: 799, 2: 799})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "#Randomly spilt dataset to traing/testing dataset with the original ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feature, \n",
    "                                                    df_class, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=df_class)\n",
    "print(\"Spliting is done!\")\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S, %D\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "######## SMOTE oversampling\n",
    "sm = SMOTE(random_state=42)\n",
    "counter = Counter(y_train)\n",
    "print(\"Before SMOTE: {}\".format(counter))\n",
    "\n",
    "X_train_new, y_train_new = sm.fit_resample(X_train, y_train)\n",
    "counter = Counter(y_train_new)\n",
    "print(\"After SMOTE: {}\".format(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.999, test=0.894) total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.999, test=0.898) total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.999, test=0.908) total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.998, test=0.932) total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=1.000, test=0.921) total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.997, test=0.900) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.998, test=0.894) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.997, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.996, test=0.926) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=0.997, test=0.927) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60;, score=(train=0.971, test=0.914) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60;, score=(train=0.971, test=0.919) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60;, score=(train=0.968, test=0.906) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60;, score=(train=0.968, test=0.928) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60;, score=(train=0.968, test=0.916) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=40;, score=(train=0.995, test=0.906) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=40;, score=(train=0.995, test=0.900) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=40;, score=(train=0.995, test=0.904) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=40;, score=(train=0.990, test=0.934) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=40;, score=(train=0.995, test=0.927) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=90;, score=(train=0.963, test=0.904) total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=90;, score=(train=0.964, test=0.919) total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=90;, score=(train=0.964, test=0.908) total time=   0.2s\n",
      "[CV 4/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=90;, score=(train=0.961, test=0.930) total time=   0.2s\n",
      "[CV 5/5] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=90;, score=(train=0.961, test=0.925) total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.889) total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.900) total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.910) total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.930) total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.925) total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.900) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.906) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=0.928) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=0.925) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=80;, score=(train=0.987, test=0.908) total time=   0.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=80;, score=(train=0.988, test=0.921) total time=   0.2s\n",
      "[CV 3/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=80;, score=(train=0.985, test=0.910) total time=   0.2s\n",
      "[CV 4/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=80;, score=(train=0.988, test=0.934) total time=   0.2s\n",
      "[CV 5/5] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=80;, score=(train=0.984, test=0.920) total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.981, test=0.908) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.980, test=0.913) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.980, test=0.906) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.983, test=0.940) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.982, test=0.919) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.982, test=0.906) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.983, test=0.913) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.982, test=0.906) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.988, test=0.940) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.987, test=0.919) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30;, score=(train=0.936, test=0.901) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30;, score=(train=0.928, test=0.912) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30;, score=(train=0.932, test=0.907) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30;, score=(train=0.926, test=0.913) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30;, score=(train=0.933, test=0.920) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.933, test=0.895) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.931, test=0.918) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.933, test=0.907) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.926, test=0.913) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=70;, score=(train=0.931, test=0.920) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.998, test=0.904) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.997, test=0.900) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.997, test=0.906) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.996, test=0.924) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=40;, score=(train=0.996, test=0.931) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=1.000, test=0.889) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.999, test=0.902) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=1.000, test=0.910) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.999, test=0.932) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=1.000, test=0.923) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.902) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.898) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.906) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.932) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.921) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.984, test=0.906) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.986, test=0.919) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.985, test=0.910) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.984, test=0.928) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=60;, score=(train=0.985, test=0.923) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.972, test=0.900) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.974, test=0.913) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.970, test=0.912) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.972, test=0.938) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, max_depth=25, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=30;, score=(train=0.970, test=0.916) total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.900) total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.898) total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.904) total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.928) total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.925) total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.911) total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.992, test=0.906) total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.989, test=0.910) total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.987, test=0.940) total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=25, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.923) total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.993, test=0.906) total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.994, test=0.907) total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.992, test=0.904) total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.990, test=0.930) total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.993, test=0.923) total time=   0.1s\n",
      "Best Parameters:  {'n_estimators': 80, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}  \n",
      "\n",
      "Bestf1_score: 0.9187741452966071 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "# 5 * 2 * 4 * 3 * 3 = 360\n",
    "\n",
    "# Define model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "#Define parameter\n",
    "#10x2x5x2x2x2=800\n",
    "n_estimators =  [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)] # number of trees in the random forest\n",
    "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "max_depth = [int(x) for x in np.linspace(start = 5, stop = 25, num = 5)] # maximum number of levels allowed in each decision tree\n",
    "min_samples_split = [2, 5] # minimum sample number to split a node\n",
    "min_samples_leaf = [1, 2] # minimum sample number that can be stored in a leaf node\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "#Create Stratified K-fold cross validation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5 n_repeats=3, random_state=1)\n",
    "\n",
    "\n",
    "##Grid search\n",
    "rf_random = RandomizedSearchCV(estimator = rf_model, \n",
    "                               param_distributions = random_grid, \n",
    "                               scoring='f1_macro', \n",
    "                               cv=5, \n",
    "                               #verbose=2, \n",
    "                               verbose=3, \n",
    "                               return_train_score=True, \n",
    "                               n_iter = 20,  #The number of parameter settings that are tried \n",
    "                               random_state=35,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "rf_result = rf_random.fit(X_train_new, y_train_new)\n",
    "\n",
    "# this prints the contents of the parameters in the random grid\n",
    "#print ('Random grid: ', rf_random, '\\n')\n",
    "\n",
    "# print the best parameters\n",
    "print ('Best Parameters: ', rf_random.best_params_, ' \\n')\n",
    "\n",
    "print('Bestf1_score:', rf_random.best_score_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/pod/2/li-lab/Ziwei/Nanopore/daily/test/test.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best parameter\n",
    "#https://stackoverflow.com/questions/34143829/sklearn-how-to-save-a-model-created-from-a-pipeline-and-gridsearchcv-using-jobli\n",
    "import joblib\n",
    "joblib.dump(rf_random.best_estimator_, os.path.join(input_path,'test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load model with best parameter\n",
    "import pandas as pd\n",
    "#test = pd.read_pickle(os.path.join(input_path,'test.pkl'))\n",
    "#test = pickle.load(open(os.path.join(input_path,'test.pkl'), 'rb'))\n",
    "test = joblib.load(os.path.join(input_path,'test.pkl'))\n",
    "result = test.score(X_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hyper-parameter tuning is done!\n",
      "Current Time = 11:19:44, 09/29/21\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, rf_random.predict(X_test)\n",
    "\n",
    "print(\" Hyper-parameter tuning is done!\")\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S, %D\")\n",
    "print(\"Current Time =\", current_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159563</td>\n",
       "      <td>0.020393</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896927</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>15</td>\n",
       "      <td>0.995309</td>\n",
       "      <td>0.996867</td>\n",
       "      <td>0.995311</td>\n",
       "      <td>0.994514</td>\n",
       "      <td>0.993257</td>\n",
       "      <td>0.995052</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095886</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900070</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>7</td>\n",
       "      <td>0.953201</td>\n",
       "      <td>0.950103</td>\n",
       "      <td>0.952770</td>\n",
       "      <td>0.955576</td>\n",
       "      <td>0.952892</td>\n",
       "      <td>0.952908</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070591</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897319</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>12</td>\n",
       "      <td>0.989307</td>\n",
       "      <td>0.989789</td>\n",
       "      <td>0.992171</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>0.989723</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142487</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899530</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>8</td>\n",
       "      <td>0.949218</td>\n",
       "      <td>0.945530</td>\n",
       "      <td>0.944465</td>\n",
       "      <td>0.947214</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>0.947553</td>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.177670</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>20</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.052913</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892056</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>19</td>\n",
       "      <td>0.996872</td>\n",
       "      <td>0.997652</td>\n",
       "      <td>0.993748</td>\n",
       "      <td>0.990858</td>\n",
       "      <td>0.992459</td>\n",
       "      <td>0.994318</td>\n",
       "      <td>0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129119</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897971</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979012</td>\n",
       "      <td>0.978869</td>\n",
       "      <td>0.974284</td>\n",
       "      <td>0.979064</td>\n",
       "      <td>0.977034</td>\n",
       "      <td>0.977652</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.070572</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901212</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>5</td>\n",
       "      <td>0.976243</td>\n",
       "      <td>0.977236</td>\n",
       "      <td>0.979830</td>\n",
       "      <td>0.978291</td>\n",
       "      <td>0.974093</td>\n",
       "      <td>0.977138</td>\n",
       "      <td>0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897231</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>13</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.988206</td>\n",
       "      <td>0.987585</td>\n",
       "      <td>0.989834</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.986458</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.045053</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902704</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>2</td>\n",
       "      <td>0.929366</td>\n",
       "      <td>0.923816</td>\n",
       "      <td>0.927647</td>\n",
       "      <td>0.934822</td>\n",
       "      <td>0.932701</td>\n",
       "      <td>0.929670</td>\n",
       "      <td>0.003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.102743</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903915</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931156</td>\n",
       "      <td>0.922872</td>\n",
       "      <td>0.925956</td>\n",
       "      <td>0.930684</td>\n",
       "      <td>0.931859</td>\n",
       "      <td>0.928506</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.071333</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896956</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>14</td>\n",
       "      <td>0.995317</td>\n",
       "      <td>0.996867</td>\n",
       "      <td>0.994524</td>\n",
       "      <td>0.992156</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.107141</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894889</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.089233</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.097041</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901365</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>4</td>\n",
       "      <td>0.980591</td>\n",
       "      <td>0.978908</td>\n",
       "      <td>0.972206</td>\n",
       "      <td>0.972686</td>\n",
       "      <td>0.975513</td>\n",
       "      <td>0.975981</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.048632</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901839</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954618</td>\n",
       "      <td>0.950882</td>\n",
       "      <td>0.957570</td>\n",
       "      <td>0.957580</td>\n",
       "      <td>0.958609</td>\n",
       "      <td>0.955852</td>\n",
       "      <td>0.002820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895768</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>16</td>\n",
       "      <td>0.992918</td>\n",
       "      <td>0.990565</td>\n",
       "      <td>0.991650</td>\n",
       "      <td>0.987702</td>\n",
       "      <td>0.988030</td>\n",
       "      <td>0.990173</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900118</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>6</td>\n",
       "      <td>0.986930</td>\n",
       "      <td>0.988177</td>\n",
       "      <td>0.987977</td>\n",
       "      <td>0.986367</td>\n",
       "      <td>0.987264</td>\n",
       "      <td>0.987343</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.088088</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898076</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>9</td>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.990548</td>\n",
       "      <td>0.988308</td>\n",
       "      <td>0.989292</td>\n",
       "      <td>0.987284</td>\n",
       "      <td>0.988789</td>\n",
       "      <td>0.001088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.159563      0.020393         0.010009        0.001946   \n",
       "1        0.088800      0.000970         0.006080        0.000245   \n",
       "2        0.095886      0.000871         0.006712        0.000132   \n",
       "3        0.070591      0.001414         0.004885        0.000079   \n",
       "4        0.142487      0.000607         0.009411        0.000275   \n",
       "5        0.177670      0.002127         0.011019        0.000213   \n",
       "6        0.052913      0.001313         0.003939        0.000146   \n",
       "7        0.129119      0.000771         0.008740        0.000137   \n",
       "8        0.070572      0.001164         0.005041        0.000184   \n",
       "9        0.105200      0.001374         0.007028        0.000225   \n",
       "10       0.045053      0.001396         0.003725        0.000133   \n",
       "11       0.102743      0.000789         0.007129        0.000213   \n",
       "12       0.071333      0.001057         0.004944        0.000176   \n",
       "13       0.107141      0.001604         0.007086        0.000119   \n",
       "14       0.089233      0.000809         0.006016        0.000196   \n",
       "15       0.097041      0.001043         0.006643        0.000257   \n",
       "16       0.048632      0.000552         0.003838        0.000163   \n",
       "17       0.018386      0.000513         0.002001        0.000097   \n",
       "18       0.018186      0.000628         0.002038        0.000130   \n",
       "19       0.088088      0.001505         0.005916        0.000193   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                  70                       5                      1   \n",
       "1                  50                       2                      2   \n",
       "2                  60                       5                      2   \n",
       "3                  40                       5                      2   \n",
       "4                  90                       5                      2   \n",
       "5                 100                       5                      1   \n",
       "6                  30                       2                      2   \n",
       "7                  80                       5                      1   \n",
       "8                  40                       2                      2   \n",
       "9                  60                       5                      1   \n",
       "10                 30                       2                      1   \n",
       "11                 70                       5                      1   \n",
       "12                 40                       2                      2   \n",
       "13                 60                       5                      1   \n",
       "14                 50                       5                      1   \n",
       "15                 60                       5                      1   \n",
       "16                 30                       2                      2   \n",
       "17                 10                       2                      2   \n",
       "18                 10                       5                      2   \n",
       "19                 50                       5                      2   \n",
       "\n",
       "   param_max_features param_max_depth param_bootstrap  ... mean_test_score  \\\n",
       "0                auto              15           False  ...        0.897698   \n",
       "1                sqrt              25           False  ...        0.896927   \n",
       "2                auto              25            True  ...        0.900070   \n",
       "3                auto              20           False  ...        0.897319   \n",
       "4                auto              10            True  ...        0.899530   \n",
       "5                auto              25           False  ...        0.891204   \n",
       "6                auto              20           False  ...        0.892056   \n",
       "7                sqrt              20            True  ...        0.897971   \n",
       "8                sqrt              10           False  ...        0.901212   \n",
       "9                sqrt              10           False  ...        0.897231   \n",
       "10               auto               5           False  ...        0.902704   \n",
       "11               auto               5           False  ...        0.903915   \n",
       "12               auto              20           False  ...        0.896956   \n",
       "13               auto              20           False  ...        0.894889   \n",
       "14               auto              15           False  ...        0.894389   \n",
       "15               sqrt              15            True  ...        0.901365   \n",
       "16               sqrt              25            True  ...        0.901839   \n",
       "17               auto              20           False  ...        0.895768   \n",
       "18               auto              25           False  ...        0.900118   \n",
       "19               sqrt              15           False  ...        0.898076   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.007097               11            0.999216            1.000000   \n",
       "1         0.007625               15            0.995309            0.996867   \n",
       "2         0.009937                7            0.953201            0.950103   \n",
       "3         0.010366               12            0.989307            0.989789   \n",
       "4         0.009703                8            0.949218            0.945530   \n",
       "5         0.006440               20            0.999216            0.999217   \n",
       "6         0.005248               19            0.996872            0.997652   \n",
       "7         0.007887               10            0.979012            0.978869   \n",
       "8         0.007930                5            0.976243            0.977236   \n",
       "9         0.006356               13            0.983824            0.988206   \n",
       "10        0.009481                2            0.929366            0.923816   \n",
       "11        0.009981                1            0.931156            0.922872   \n",
       "12        0.007090               14            0.995317            0.996867   \n",
       "13        0.005381               17            0.999216            0.999217   \n",
       "14        0.005643               18            0.999216            1.000000   \n",
       "15        0.007454                4            0.980591            0.978908   \n",
       "16        0.009162                3            0.954618            0.950882   \n",
       "17        0.003462               16            0.992918            0.990565   \n",
       "18        0.010031                6            0.986930            0.988177   \n",
       "19        0.008571                9            0.988516            0.990548   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.000000            1.000000            0.999218   \n",
       "1             0.995311            0.994514            0.993257   \n",
       "2             0.952770            0.955576            0.952892   \n",
       "3             0.992171            0.990066            0.987281   \n",
       "4             0.944465            0.947214            0.951336   \n",
       "5             1.000000            1.000000            0.999218   \n",
       "6             0.993748            0.990858            0.992459   \n",
       "7             0.974284            0.979064            0.977034   \n",
       "8             0.979830            0.978291            0.974093   \n",
       "9             0.987585            0.989834            0.982841   \n",
       "10            0.927647            0.934822            0.932701   \n",
       "11            0.925956            0.930684            0.931859   \n",
       "12            0.994524            0.992156            0.993234   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            0.999218   \n",
       "15            0.972206            0.972686            0.975513   \n",
       "16            0.957570            0.957580            0.958609   \n",
       "17            0.991650            0.987702            0.988030   \n",
       "18            0.987977            0.986367            0.987264   \n",
       "19            0.988308            0.989292            0.987284   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.999687         0.000384  \n",
       "1           0.995052         0.001178  \n",
       "2           0.952908         0.001737  \n",
       "3           0.989723         0.001565  \n",
       "4           0.947553         0.002483  \n",
       "5           0.999530         0.000384  \n",
       "6           0.994318         0.002584  \n",
       "7           0.977652         0.001847  \n",
       "8           0.977138         0.001932  \n",
       "9           0.986458         0.002674  \n",
       "10          0.929670         0.003852  \n",
       "11          0.928506         0.003500  \n",
       "12          0.994419         0.001633  \n",
       "13          0.999687         0.000384  \n",
       "14          0.999687         0.000384  \n",
       "15          0.975981         0.003321  \n",
       "16          0.955852         0.002820  \n",
       "17          0.990173         0.002028  \n",
       "18          0.987343         0.000667  \n",
       "19          0.988789         0.001088  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(rf_result.cv_results_)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting the confusion matrix with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'True label'\n",
    "    cm.columns.name = 'Predicted label'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cmap=\"Greens\")\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_analysis(y_true, y_pred, os.path.join(input_path, 'test.png'),\n",
    "            labels = None, ymap=None, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report for the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5C</th>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.927681</td>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5mC</th>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.953317</td>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5hmC</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.876999</td>\n",
       "      <td>500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.901550</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.902399</td>\n",
       "      <td>500.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "5C             0.925373  0.930000  0.927681  200.000\n",
       "5mC            0.937198  0.970000  0.953317  200.000\n",
       "5hmC           0.782609  0.720000  0.750000  100.000\n",
       "accuracy       0.904000  0.904000  0.904000    0.904\n",
       "macro avg      0.881727  0.873333  0.876999  500.000\n",
       "weighted avg   0.901550  0.904000  0.902399  500.000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ['5C', '5mC', '5hmC']\n",
    "report = classification_report(y_true, y_pred, target_names = label, digits = 4, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
