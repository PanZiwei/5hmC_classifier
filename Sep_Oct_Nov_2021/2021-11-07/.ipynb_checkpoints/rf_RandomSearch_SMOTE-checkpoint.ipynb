{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021/10/21\n",
    "The jupypter notebook is used to test the pipleine for the ENN + SMOTE + random forest pipeline intergration from sklearn for single parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loading!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>read_id</th>\n",
       "      <th>strand</th>\n",
       "      <th>5hmC_prob</th>\n",
       "      <th>5mC_prob</th>\n",
       "      <th>5C_prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>204</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.435397</td>\n",
       "      <td>0.085058</td>\n",
       "      <td>0.479545</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>261</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.342189</td>\n",
       "      <td>0.500821</td>\n",
       "      <td>0.156990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>261</td>\n",
       "      <td>fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.577034</td>\n",
       "      <td>0.057676</td>\n",
       "      <td>0.365290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>266</td>\n",
       "      <td>3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa</td>\n",
       "      <td>-</td>\n",
       "      <td>0.065316</td>\n",
       "      <td>0.861569</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KJ477685.1</td>\n",
       "      <td>266</td>\n",
       "      <td>fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.794235</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.176880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb826a6c-c88b-45ac-9984-8b9d6bfb2f11</td>\n",
       "      <td>-</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.932103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb91267a-6661-4248-a084-554f231398c1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.964888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bb9cee29-89d0-4a68-a4b4-8fe5c000289f</td>\n",
       "      <td>-</td>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.960363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bbee6b4a-acac-4db9-bbb8-2f379918b146</td>\n",
       "      <td>-</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.961085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>J02459.1</td>\n",
       "      <td>60</td>\n",
       "      <td>bc26e861-9931-48fb-b4cb-2adc9ccbd2c0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.955738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             chr  start                               read_id strand  \\\n",
       "0     KJ477685.1    204  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "1     KJ477685.1    261  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "2     KJ477685.1    261  fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9      -   \n",
       "3     KJ477685.1    266  3e547b1a-0a3e-4475-9b70-0cbd7c8c82aa      -   \n",
       "4     KJ477685.1    266  fe8be0cc-f4c4-49f1-80db-c840a6c7dfe9      -   \n",
       "...          ...    ...                                   ...    ...   \n",
       "2492    J02459.1     60  bb826a6c-c88b-45ac-9984-8b9d6bfb2f11      -   \n",
       "2493    J02459.1     60  bb91267a-6661-4248-a084-554f231398c1      -   \n",
       "2494    J02459.1     60  bb9cee29-89d0-4a68-a4b4-8fe5c000289f      -   \n",
       "2495    J02459.1     60  bbee6b4a-acac-4db9-bbb8-2f379918b146      -   \n",
       "2496    J02459.1     60  bc26e861-9931-48fb-b4cb-2adc9ccbd2c0      -   \n",
       "\n",
       "      5hmC_prob  5mC_prob   5C_prob  label  \n",
       "0      0.435397  0.085058  0.479545      2  \n",
       "1      0.342189  0.500821  0.156990      2  \n",
       "2      0.577034  0.057676  0.365290      2  \n",
       "3      0.065316  0.861569  0.073115      2  \n",
       "4      0.794235  0.028885  0.176880      2  \n",
       "...         ...       ...       ...    ...  \n",
       "2492   0.054875  0.013023  0.932103      0  \n",
       "2493   0.030720  0.004392  0.964888      0  \n",
       "2494   0.032703  0.006934  0.960363      0  \n",
       "2495   0.035734  0.003182  0.961085      0  \n",
       "2496   0.040249  0.004014  0.955738      0  \n",
       "\n",
       "[2497 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path='/pod/2/li-lab/Ziwei/Nanopore/daily/test/'\n",
    "#df=pd.read_csv(os.path.join(input_path, 'total.Megalodon.per_read.prob.bed.gz'),compression='gzip', sep='\\t')\n",
    "df=pd.read_csv(os.path.join(input_path, 'total.test.bed'), sep='\\t')\n",
    "print(\"Data is loading!\")\n",
    "\n",
    "#Splitting the data into independent and dependent variables\n",
    "df_feature = df.loc[:,['5hmC_prob','5mC_prob','5C_prob']].values\n",
    "df_class = df.loc[:,['label']].values\n",
    "df_class = np.squeeze(df_class) #Convert the label into 1d-array\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    999\n",
       "0    999\n",
       "2    499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, GridSearchCV\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the feature\n",
    "input_path='/pod/2/li-lab/Ziwei/Nanopore/daily/test'\n",
    "#df=pd.read_csv(os.path.join(input_path, 'total.Megalodon.per_read.prob.bed.gz'),compression='gzip', sep='\\t')\n",
    "df=pd.read_csv(os.path.join(input_path, 'total.test.bed'), sep='\\t')\n",
    "\n",
    "#Splitting the data into independent and dependent variables\n",
    "df_feature = df.loc[:,['5hmC_prob','5mC_prob','5C_prob']].values\n",
    "df_class = df.loc[:,['label']].values\n",
    "df_class = np.squeeze(df_class) #Convert the label into 1d-array\n",
    "\n",
    "X = df_feature\n",
    "y = df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 499, 1: 499, 2: 499}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.bincount(y)[-1]\n",
    "key=[0,1,2]\n",
    "value = [(1*n, 1*n, n)]\n",
    "for i in value:\n",
    "    sampling_strategy = dict(zip(key, i)).copy()\n",
    "sampling_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 499, 1: 499, 2: 499})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, RandomUnderSampler\n",
    "sampler = RandomUnderSampler(random_state = 42, sampling_strategy=sampling_strategy)\n",
    "\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "print(Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before the pipeline:\n",
      " y_train:Counter({2: 399, 1: 399, 0: 399}),\n",
      " y_test: Counter({0: 100, 1: 100, 2: 100})\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,\n",
    "                                                    y_res,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y_res,\n",
    "                                                    random_state=42)\n",
    "print(\"Before the pipeline:\\n y_train:{},\\n y_test: {}\".format(Counter(y_train), Counter(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparemter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68199/2123140532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mrf_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# this prints the contents of the parameters in the random grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pod/2/li-lab/Ziwei/Anaconda3/envs/nanomodel_python3.8/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pod/2/li-lab/Ziwei/Anaconda3/envs/nanomodel_python3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \"\"\"\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pod/2/li-lab/Ziwei/Anaconda3/envs/nanomodel_python3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "# 5 * 2 * 4 * 3 * 3 = 360\n",
    "\n",
    "# Define model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "#Define parameter\n",
    "#10x2x5x2x2x2=800\n",
    "n_estimators =  [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)] # number of trees in the random forest\n",
    "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "max_depth = [int(x) for x in np.linspace(start = 5, stop = 25, num = 5)] # maximum number of levels allowed in each decision tree\n",
    "min_samples_split = [2, 5] # minimum sample number to split a node\n",
    "min_samples_leaf = [1, 2] # minimum sample number that can be stored in a leaf node\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "params = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "#Create Stratified K-fold cross validation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5 n_repeats=3, random_state=1)\n",
    "\n",
    "\n",
    "##Grid search\n",
    "#rf_random = GridSearchCV(estimator = rf_model, \n",
    "#                         param_grid = params, \n",
    "#                         scoring='f1_macro', \n",
    "#                         cv=cv, \n",
    "#                         verbose=3, \n",
    "#                         verbose=1, \n",
    "#                         return_train_score=True, \n",
    "#                         n_jobs=-1)\n",
    "\n",
    "\n",
    "##RandomSearch\n",
    "rf_random = RandomizedSearchCV(estimator = rf_model, \n",
    "                          param_distributions = params, \n",
    "                          scoring='f1_macro', \n",
    "                          cv=cv, \n",
    "                          verbose=1,   \n",
    "                          n_iter=10,  ##find parameter number\n",
    "                          return_train_score=True, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "rf_result = rf_random.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, grid.predict(X_test)\n",
    "\n",
    "# this prints the contents of the parameters in the random grid\n",
    "#print ('Random grid: ', rf_random, '\\n')\n",
    "\n",
    "cv_score = rf_result.best_score_\n",
    "test_score = rf_result.score(X_test, y_test)\n",
    "\n",
    "print ('Best Parameters: ',rf_result.best_params_, ' \\n')\n",
    "print('Best f1_score in cv:', cv_score, '\\n')\n",
    "print('Test score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save best parameter\n",
    "#https://stackoverflow.com/questions/34143829/sklearn-how-to-save-a-model-created-from-a-pipeline-and-gridsearchcv-using-jobli\n",
    "import joblib\n",
    "joblib.dump(pipe_search.best_estimator_, os.path.join(output_path,pkl_model))\n",
    "    \n",
    " ##Save the cv result \n",
    "cv_table = pd.DataFrame(pipe_result.cv_results_)\n",
    "cv_table.to_csv(os.path.join(output_path, cv_result), sep='\\t', index = True)\n",
    "    \n",
    "    ##Save the confusion matrix   \n",
    "    plot_cm(y_test, y_pred, os.path.join(output_path, cm_png), labels=None)\n",
    "    \n",
    "    ## Save the classification report\n",
    "    target_class = ['5C', '5mC', '5hmC']\n",
    "    report = classification_report(y_test, y_pred, target_names=target_class, output_dict=True)\n",
    "    report = pd.DataFrame(report).transpose()\n",
    "    report.to_csv(os.path.join(output_path, class_report), header = True, index= None, sep = ',', float_format='%.4f')\n",
    "    \n",
    "    print(\"Saving is done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imblearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the resampling strategy: RandomUnderSampler -> SMOTE\n",
    "sampler = make_pipeline(\n",
    "    RandomUnderSampler(random_state = 42, sampling_strategy={0: 500, 1:500, 2:270}),\n",
    "    SMOTE(sampling_strategy='not majority',\n",
    "          k_neighbors=100,\n",
    "          random_state = 42,\n",
    "          n_jobs = -1))\n",
    "\n",
    "X_res, y_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 500, 1: 500, 2: 500})\n"
     ]
    }
   ],
   "source": [
    "# Make the resampling strategy: RandomUnderSampler -> SMOTE\n",
    "sampler = make_pipeline(\n",
    "    RandomUnderSampler(random_state = 42, sampling_strategy={0: 500, 1:500, 2:270}),\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "\n",
    "X_res, y_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define cross-validation fold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 3, random_state = 42, shuffle = True)\n",
    "\n",
    "##define random forest model\n",
    "#https://stackoverflow.com/a/51493479\n",
    "###Build the pipeline\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "under = RandomUnderSampler(random_state = 42)\n",
    "\n",
    "over = SMOTE(sampling_strategy='not majority', random_state = 42, n_jobs = -1)\n",
    "\n",
    "steps = [('u', under), ('o', over), ('m', rf_model)]\n",
    "\n",
    "pipeline = imbpipeline(steps=steps)\n",
    "\n",
    "print(Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 450, 1: 450, 2: 450})\n"
     ]
    }
   ],
   "source": [
    "# Make the resampling strategy: ENN -> SMOTE\n",
    "ENN_SMOTE_sampler = make_pipeline(\n",
    "    EditedNearestNeighbours(n_neighbors = 100,\n",
    "                            n_jobs = -1),\n",
    "    SMOTE(sampling_strategy='not majority',\n",
    "          k_neighbors=100,\n",
    "          random_state = 42,\n",
    "          n_jobs = -1))\n",
    "\n",
    "X_res_train, y_res_train = ENN_SMOTE_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(Counter(y_res_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENN+SMOTE: Test with multiple parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'u', 'o', 'm', 'u__kind_sel', 'u__n_jobs', 'u__n_neighbors', 'u__sampling_strategy', 'o__k_neighbors', 'o__n_jobs', 'o__random_state', 'o__sampling_strategy', 'm__bootstrap', 'm__ccp_alpha', 'm__class_weight', 'm__criterion', 'm__max_depth', 'm__max_features', 'm__max_leaf_nodes', 'm__max_samples', 'm__min_impurity_decrease', 'm__min_impurity_split', 'm__min_samples_leaf', 'm__min_samples_split', 'm__min_weight_fraction_leaf', 'm__n_estimators', 'm__n_jobs', 'm__oob_score', 'm__random_state', 'm__verbose', 'm__warm_start'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "# Define cross-validation fold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 3, random_state = 42, shuffle = True)\n",
    "\n",
    "##define random forest model\n",
    "#https://stackoverflow.com/a/51493479\n",
    "###Build the pipeline\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "under = EditedNearestNeighbours(n_jobs = -1)\n",
    "over = SMOTE(sampling_strategy='not majority', random_state = 42, n_jobs = -1)\n",
    "steps = [('u', under), ('o', over), ('m', rf_model)]\n",
    "\n",
    "pipeline = imbpipeline(steps=steps)\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/51480776/how-to-implement-ratio-based-smote-oversampling-while-cv-ing-dataset\n",
    "params = {'u__n_neighbors' : [20,50,100],\n",
    "          'o__k_neighbors':[20, 30, 40],\n",
    "          'm__max_depth' : list(range(2,5)),\n",
    "          'm__max_features' : ['auto','sqrt'],\n",
    "          'm__bootstrap' : [True, False]\n",
    "         }\n",
    "\n",
    "grid = RandomizedSearchCV(estimator = pipeline, \n",
    "                          param_distributions = params, \n",
    "                          scoring='f1_macro', \n",
    "                          cv=stratified_kfold, \n",
    "                          verbose=3,   \n",
    "                          n_iter=10,\n",
    "                          return_train_score=True, \n",
    "                          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=4, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=50;, score=(train=0.789, test=0.774) total time=   2.1s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=4, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=50;, score=(train=0.739, test=0.744) total time=   1.0s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=4, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=50;, score=(train=0.769, test=0.771) total time=   1.0s\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=2, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=100;, score=(train=0.715, test=0.674) total time=   3.9s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=2, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=100;, score=(train=0.714, test=0.719) total time=   2.0s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=2, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=100;, score=(train=0.676, test=0.715) total time=   1.7s\n",
      "[CV 1/3] END m__bootstrap=False, m__max_depth=3, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=100;, score=(train=0.676, test=0.625) total time=   1.1s\n",
      "[CV 2/3] END m__bootstrap=False, m__max_depth=3, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=100;, score=(train=0.670, test=0.687) total time=   1.0s\n",
      "[CV 3/3] END m__bootstrap=False, m__max_depth=3, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=100;, score=(train=0.656, test=0.671) total time=   6.0s\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=2, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.861, test=0.852) total time=   4.0s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=2, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.871, test=0.853) total time=   1.0s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=2, m__max_features=auto, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.875, test=0.889) total time=   3.1s\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=2, m__max_features=sqrt, o__k_neighbors=20, u__n_neighbors=50;, score=(train=0.808, test=0.784) total time=   4.0s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=2, m__max_features=sqrt, o__k_neighbors=20, u__n_neighbors=50;, score=(train=0.743, test=0.739) total time=   2.2s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=2, m__max_features=sqrt, o__k_neighbors=20, u__n_neighbors=50;, score=(train=0.775, test=0.801) total time=   0.2s\n",
      "[CV 1/3] END m__bootstrap=False, m__max_depth=4, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.864, test=0.832) total time=   0.3s\n",
      "[CV 2/3] END m__bootstrap=False, m__max_depth=4, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.836, test=0.844) total time=   0.2s\n",
      "[CV 3/3] END m__bootstrap=False, m__max_depth=4, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.859, test=0.856) total time=  14.6s\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=3, m__max_features=sqrt, o__k_neighbors=30, u__n_neighbors=100;, score=(train=0.710, test=0.667) total time=   4.3s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=3, m__max_features=sqrt, o__k_neighbors=30, u__n_neighbors=100;, score=(train=0.676, test=0.692) total time=   4.9s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=3, m__max_features=sqrt, o__k_neighbors=30, u__n_neighbors=100;, score=(train=0.661, test=0.674) total time=   1.3s\n",
      "[CV 1/3] END m__bootstrap=False, m__max_depth=2, m__max_features=auto, o__k_neighbors=20, u__n_neighbors=20;, score=(train=0.837, test=0.832) total time=   2.4s\n",
      "[CV 2/3] END m__bootstrap=False, m__max_depth=2, m__max_features=auto, o__k_neighbors=20, u__n_neighbors=20;, score=(train=0.804, test=0.804) total time=   1.0s\n",
      "[CV 3/3] END m__bootstrap=False, m__max_depth=2, m__max_features=auto, o__k_neighbors=20, u__n_neighbors=20;, score=(train=0.875, test=0.889) total time=   6.9s\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=3, m__max_features=auto, o__k_neighbors=20, u__n_neighbors=100;, score=(train=0.710, test=0.667) total time=   3.0s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=3, m__max_features=auto, o__k_neighbors=20, u__n_neighbors=100;, score=(train=0.676, test=0.695) total time=   5.9s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=3, m__max_features=auto, o__k_neighbors=20, u__n_neighbors=100;, score=(train=0.667, test=0.677) total time=   2.0s\n",
      "[CV 1/3] END m__bootstrap=True, m__max_depth=4, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.871, test=0.848) total time=   2.0s\n",
      "[CV 2/3] END m__bootstrap=True, m__max_depth=4, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.841, test=0.844) total time=   6.0s\n",
      "[CV 3/3] END m__bootstrap=True, m__max_depth=4, m__max_features=sqrt, o__k_neighbors=40, u__n_neighbors=20;, score=(train=0.857, test=0.859) total time=   6.6s\n"
     ]
    }
   ],
   "source": [
    "result = grid.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
