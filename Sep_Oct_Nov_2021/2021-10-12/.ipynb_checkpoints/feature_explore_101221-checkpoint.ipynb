{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Summary\n",
    "\n",
    "The jupyter notebook is used to help write the python file in `utilis` floder\n",
    "\n",
    "For single fast5 feature extraction, see daily/2021-10-05/feature_100521.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import h5py\n",
    "import logging\n",
    "import statsmodels\n",
    "from datetime import datetime\n",
    "from statsmodels import robust\n",
    "\n",
    "from utils import process_helper, fast5_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract signal, align info, event from Single fast5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path='/pod/2/li-lab/Ziwei/Nanopore/daily/test/test'\n",
    "fast5_fn='00000156-e575-4fb7-9053-d00dbe5c8d9c.fast5'\n",
    "\n",
    "signal_group='Raw/Reads'\n",
    "corr_group='RawGenomeCorrected_001' #tombo resquiggle save location\n",
    "basecall_group='Basecall_1D_001' #has to be save in the tombo requiggle step\n",
    "basecall_subgroup='BaseCalled_template' #Attention: the basecall_subgroup can be 'basecalled_compl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(input_path, fast5_fn)\n",
    "fast5 = fast5_parser.raw_fast5(path, corr_group, basecall_group, basecall_subgroup, signal_group)\n",
    "readid, fast5_signal = fast5.fast5_signal()\n",
    "event = fast5.fast5_event()\n",
    "chrom, strand, start, read_strand = fast5.fast5_align()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale signal\n",
    "Copy from feature_100521.ipynb\n",
    "\n",
    "## Define signal rescalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal rescalling\n",
    "#current in pA = (signal_value + channels 0pA adc) * digitisable range in pA / digitisation\n",
    "#https://github.com/grimbough/IONiseR/blob/47d8ab1e1d798f3591407be679076a1a5b5d9dd2/R/squiggle.R#L81\n",
    "\n",
    "#channels 0pA adc: /UniqueGlobalKey/channel_id/{offset}\n",
    "#digitisable range in pA: /UniqueGlobalKey/channel_id/{range}\n",
    "#digitisation: /UniqueGlobalKey/channel_id/{digitisation}\n",
    "\n",
    "def fast5_rescale(path, fast5_signal, channel_group='UniqueGlobalKey/channel_id'):\n",
    "    try:\n",
    "        f5 = h5py.File(path, mode=\"r\")\n",
    "    except IOError:\n",
    "        raise IOError('Error opening file')\n",
    "    \n",
    "    channel = f5[f'/{channel_group}']\n",
    "    channel_attr = dict(list(channel.attrs.items()))\n",
    "    raw_signal = np.array((fast5_signal + channel_attr['offset']) * channel_attr['range'] / channel_attr['digitisation']) \n",
    "    return raw_signal\n",
    "\n",
    "# Signal normalization with mad method\n",
    "def fast5_normalized_signal(signal, method='mad'):\n",
    "    if signal is not None:\n",
    "        if method == 'mad':\n",
    "            #assuming a normal distribution \n",
    "            #https://stackoverflow.com/a/40619633\n",
    "            shift, scale = np.median(signal), np.float(statsmodels.robust.mad(signal))\n",
    "        elif method == 'zscore':\n",
    "            shift, scale = np.mean(signal), np.float(np.std(signal))\n",
    "        else:\n",
    "            raise ValueError('Normalized method not recogized')\n",
    "            \n",
    "        #signal normalization: https://nanoporetech.github.io/tombo/resquiggle.html#tombo-fast5-format\n",
    "        # There may be problem after tombo 1.3, see explanation above\n",
    "        norm_signal = (signal - shift) / scale #POTENTIAL ISSUE!\n",
    "        assert len(signal) == len(norm_signal)\n",
    "        norm_signal = np.around(norm_signal, 6)\n",
    "        return norm_signal\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ont_fast5_api.conversion_tools.conversion_utils import get_fast5_file_list\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from pyfaidx import Fasta\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtract single fast5 file\n",
    "fast5 = fast5_parser.raw_fast5(path, corr_group, basecall_group, basecall_subgroup, signal_group)\n",
    "\n",
    "#Extract event information: #Raw signal --> Normalization\n",
    "event = fast5.fast5_event()\n",
    "raw_signal = fast5_rescale(path, fast5_signal)\n",
    "norm_signal = fast5_normalized_signal(raw_signal,  method='mad')\n",
    "\n",
    "basecalled_seq, raw_signal_list, norm_signal_list = \"\", [], []\n",
    "for e in event:\n",
    "#    print(e)\n",
    "    basecalled_seq += e[2]\n",
    "#    print(norm_signal[e[0]:(e[0] + e[1])])\n",
    "    norm_signal_list.append(norm_signal[e[0]:(e[0] + e[1])]) #event start position: end position(start+length)\n",
    "    raw_signal_list.append(raw_signal[e[0]:(e[0] + e[1])])\n",
    "    assert len(norm_signal_list) == len(raw_signal_list)\n",
    "\n",
    "# Extract other information\n",
    "readid, fast5_signal = fast5.fast5_signal() #get readid\n",
    "chrom, strand, start, read_strand = fast5.fast5_align()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATTTCTGAAG'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basecalled_seq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://2-bitbio.com/2018/06/one-hot-encode-dna-sequence-using.html\n",
    "# https://gist.github.com/rachidelfermi/7fce95fd67e67fa47681e2f7d206c5a3\n",
    "basepair = {'A': 'T',\n",
    "            'C': 'G', \n",
    "            'G': 'C', \n",
    "            'T': 'A'}\n",
    "\n",
    "\n",
    "class hot_dna:\n",
    "    def __init__(self, seq):\n",
    "        seq_array = np.array(list(seq))\n",
    "        #integer encode the sequence\n",
    "        seq_integer = LabelEncoder().fit_transform(seq_array) \n",
    "\n",
    "        #reshape because that's what OneHotEncoder likes\n",
    "        seq_integer = seq_integer.reshape(len(seq_integer), 1)\n",
    "        seq_1hot = OneHotEncoder(sparse=False).fit_transform(seq_integer)\n",
    "        \n",
    "        self._seq = seq_array\n",
    "        self._integer = seq_integer\n",
    "        self._1hot = seq_1hot\n",
    "        \n",
    "seq_1hot = hot_dna(basecalled_seq)._1hot\n",
    "seq_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get refererence length \n",
    "The same function as `get_contig2len` in DeepSignal, but more straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_length(ref_path):\n",
    "    ref_length = dict()\n",
    "    \n",
    "    #case-insensitive, and to eliminate a potentially large else-if chain:\n",
    "    while ref_path.lower().endswith(('.fasta', '.fa')) is True:\n",
    "        try:\n",
    "            for ref in Fasta(ref_path,\"fasta\"):\n",
    "                ref_length[ref.name] = len(ref) #add ref_name:ref_length pair into dictionary\n",
    "            return ref_length\n",
    "        except TypeError:\n",
    "            print(\"The reference must be .fa or .fasta format!\")\n",
    "\n",
    "ref_path = '/pod/2/li-lab/Ziwei/Nanopore/data/reference/T4_147.fa'\n",
    "ref_length = get_ref_length(ref_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define put_file_in_queue\n",
    "I borrow the code from `_fill_files_queue` from Deepsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_file_in_queue(fast5_q, fast5_file, batch_size):\n",
    "    for i in np.arange(0, len(fast5_file), batch_size):\n",
    "        fast5_q.put(fast5_file[i:(i+batch_size)])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define process_fast5 function\n",
    "\n",
    "I modified the code `_extract_preprocess` from Deepsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_helper(fast5_path, ref_path, \n",
    "                      motif = 'CG', batch_size = 100):\n",
    "\n",
    "    #batch_size: number of fast5 files to be processed by each process one time\n",
    "    \n",
    "    #Extract fast5 files in a list \n",
    "    fast5_files = get_fast5_file_list(fast5_path, recursive=True)\n",
    "    print(\"Find {} fast5 files!\".format(len(fast5_files)))\n",
    "\n",
    "    print(\"Read genome reference..\")\n",
    "    ref_length = get_ref_length(ref_path)\n",
    "\n",
    "    fast5_q = multiprocessing.Queue()\n",
    "    put_file_in_queue(fast5_q, fast5_files, batch_size)\n",
    "    \n",
    "    print(\"Preprocess is done!\")\n",
    "\n",
    "    return motif, ref_length, fast5_q, len(fast5_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 3 fast5 files!\n",
      "Read genome reference..\n",
      "Preprocess is done!\n"
     ]
    }
   ],
   "source": [
    "fast5_path = '/pod/2/li-lab/Ziwei/Nanopore/daily/test/test'\n",
    "ref_path = '/pod/2/li-lab/Ziwei/Nanopore/data/reference/hg38.fa'\n",
    "\n",
    "motif, ref_length, fast5_q, fast5_length = preprocess_helper(fast5_path, ref_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 00:02:57, 10/13/21\n",
      "Find 3 fast5 files!\n",
      "Read genome reference..\n",
      "Preprocess is done!\n",
      "Getting features from nanopore reads...\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S, %D\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "motif, ref_length, fast5_q, fast5_length = preprocess_helper(fast5_path, ref_path)\n",
    "\n",
    "feature = multiprocessing.Queue()\n",
    "error = multiprocessing.Queue()\n",
    "    \n",
    "print('Getting features from nanopore reads...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path='/pod/2/li-lab/Ziwei/Nanopore/daily/test/test'\n",
    "fast5_fn='00000156-e575-4fb7-9053-d00dbe5c8d9c.fast5'\n",
    "\n",
    "signal_group='Raw/Reads'\n",
    "corr_group='RawGenomeCorrected_001' #tombo resquiggle save location\n",
    "basecall_group='Basecall_1D_001' #has to be save in the tombo requiggle step\n",
    "basecall_subgroup='BaseCalled_template' #Attention: the basecall_subgroup can be 'basecalled_compl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open multiple fast5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.661999 0.312264 0.187358 ... 1.311508 1.286527 1.13664 ]\n",
      "File 00047d2f-1825-4151-a702-f01d559f22ab.fast5 didn't have event info\n",
      "\n",
      "File 00047d2f-1825-4151-a702-f01d559f22ab.fast5 didn't have alignment info\n",
      "[-0.343161 -0.283996 -0.141998 ...  1.514644  1.467311  3.064787]\n",
      "[-0.196215 -0.220742  0.183952 ... -1.115974 -0.858442  4.010148]\n"
     ]
    }
   ],
   "source": [
    "input_path='/pod/2/li-lab/Ziwei/Nanopore/daily/test/test'\n",
    "from ont_fast5_api.conversion_tools.conversion_utils import get_fast5_file_list\n",
    "\n",
    "fast5_list = get_fast5_file_list(input_path,recursive=True)\n",
    "\n",
    "for fast5_file in fast5_list:\n",
    "#    print(fast5_file)\n",
    "    fast5 = fast5_parser.raw_fast5(fast5_file, corr_group, basecall_group, basecall_subgroup, signal_group)\n",
    "    readid, fast5_signal = fast5.fast5_signal()\n",
    "    event = fast5.fast5_event()\n",
    "    chrom, strand, start, read_strand = fast5.fast5_align()\n",
    "    \n",
    "    raw_signal = fast5_rescale(fast5_file, fast5_signal)\n",
    "    norm_signal = fast5_normalized_signal(raw_signal,  method='mad')\n",
    "    \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'G'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif='CG'\n",
    "set(motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'G'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(set(motif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
