{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process the dataset\n",
    "input_path='/fastscratch/c-panz/2021-09-13/test'\n",
    "df_T4=pd.read_csv(os.path.join(input_path, 'T4.test.bed'), sep='\\t')\n",
    "df_lambda=pd.read_csv(os.path.join(input_path, 'lambda.test.bed'), sep='\\t')\n",
    "df_5mClambda=pd.read_csv(os.path.join(input_path, 'lambda_5mC.test.bed'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the label column\n",
    "df_T4['label'] = '5hmC'\n",
    "df_lambda['label'] = '5C'\n",
    "df_5mClambda['label'] = '5mC'\n",
    "# Merge the dataset \n",
    "df = pd.concat([df_T4, df_5mClambda, df_lambda])\n",
    "\n",
    "# Create label column\n",
    "# Createa a label with representations: 5C = 0, 5mC = 1, 5hmC = 2\n",
    "df['label'] = df['label'].map({'5C':0, '5mC':1, '5hmC':2 })\n",
    "df.to_csv(os.path.join(input_path, 'total.test.bed'), sep='\\t', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Splitting the data into independent and dependent variables\n",
    "df_feature = df.loc[:,['5hmC_prob','5mC_prob','5C_prob']].values\n",
    "df_class = df.loc[:,['label']].values\n",
    "df_class = np.squeeze(df_class) #Convert the label into 1d-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.931\n",
      "Mean recall_macro: 0.931\n",
      "Mean f1_macro: 0.931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mean\n",
    "\n",
    "# https://medium.com/sfu-cspmp/surviving-in-a-random-forest-with-imbalanced-datasets-b98b963d52eb\n",
    "# Build the random forest model\n",
    "example_params = {\n",
    "        'n_estimators': 20,\n",
    "        'max_depth': 5,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "rf_model = RandomForestClassifier(**example_params)\n",
    "\n",
    "#Create Stratified K-fold cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Randomly spilt dataset to traing/testing dataset with the original ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feature, \n",
    "                                                    df_class, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=df_class)\n",
    "\n",
    "\n",
    "#https://medium.com/sfu-cspmp/surviving-in-a-random-forest-with-imbalanced-datasets-b98b963d52eb\n",
    "scoring = ('accuracy', 'recall_macro', 'f1_macro')\n",
    "\n",
    "#Evaluate SRF model\n",
    "scores = cross_validate(rf_model, X_train, y_train, scoring=scoring, cv=cv)\n",
    "#Get average evaluation metrics\n",
    "print('Mean accuracy: %.3f' % mean(scores['test_accuracy']))\n",
    "print('Mean recall_macro: %.3f' % mean(scores['test_recall_macro']))\n",
    "print('Mean f1_macro: %.3f' % mean(scores['test_f1_macro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mean\n",
    "\n",
    "# https://medium.com/sfu-cspmp/surviving-in-a-random-forest-with-imbalanced-datasets-b98b963d52eb\n",
    "# Build the random forest model\n",
    "example_params = {\n",
    "        'n_estimators': 20,\n",
    "        'max_depth': 5,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "rf_model = RandomForestClassifier(**example_params)\n",
    "\n",
    "#Create Stratified K-fold cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Randomly spilt dataset to traing/testing dataset with the original ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feature, \n",
    "                                                    df_class, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=df_class)\n",
    "\n",
    "\n",
    "#https://medium.com/sfu-cspmp/surviving-in-a-random-forest-with-imbalanced-datasets-b98b963d52eb\n",
    "scoring = ('accuracy', 'recall_macro', 'f1_macro')\n",
    "\n",
    "\n",
    "cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='recall_macro', n_jobs=-1)\n",
    "print('test4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
