# Nov, 2021

## Import results
Feature files extracted by DeepSignal: `/pod/2/li-lab/Ziwei/Nanopore/results/deepsignal0.1.9_guppy5.0.11`

## 2021-11-29:  DeepSignal custom updates
Retrain the model with minimum feature input requirement

## 2021-11-27: Other - Install pytorch
Create a conda environment for pytorch

## 2021-11-26: DeepSignal custom updates
Install DeepSignal custom env -> Extract features with 3-class label -> train a 3-way classifier

## 2021-11-24: Other: Install DeepSimulator
[DeepSimulator](https://github.com/lykaust15/DeepSimulator): a deep learning based Nanopore simulator which can simulate the process of Nanopore sequencing.

## 2021-11-23: Other: Download E.coli
Download the [E.coli dataset from R9](https://www.ebi.ac.uk/ena/browser/view/PRJEB13021?show=reads) used in METEORE

Accession PRJEB13021 (ERR1676719 for negative control and ERR1676720 for positive control): https://github.com/comprna/METEORE/issues/21#issue-1032269641

## 2021-11-22: DeepSignal custom
Use DeepSignal custom model to extract features with 3-class label -> train a 3-way classifier

## 2021-11-21: DeepSignal

Use DeepSignal default model to train a binary model for 5mC_lambda/5C_lambda and evaluate the performance

Install DeepSignal v0.1.9:`0_install_deepsignal_v0.1.9.sh` -> Extract feature files -> Prepare training and testing datasets -> Train the model

!!Attention: The DeepSignal has a minimum feature number for samples: batch_size(512)*display_step(default=100) samples, more discussion: https://github.com/bioinfomaticsCSU/deepsignal/issues/74#issuecomment-975197726


## 2021-11-15: Other

Help Yang to implement nanome demo with singularity following the tutorial: https://www.youtube.com/watch?v=xwk1zRU42_4


## 2021-11-13: Megalodon rf - Apply SMOTE on training dataset, apply ratio only on validation and testing
Split the sample into training, validation, testing -> Downsamping validation and testing with specific ratio -> Train the model on training dataset with SMOTE+rf -> RandomSearch/GridSearch for best paramter -> Apply the result on validaiton/testing dataset

Grid Search:`rf_ratio_GridSearch.sh`

Random Search: `rf_ratio_RandomSearch.sh`

## 2021-11-10:  Megalodon rf - load saved model
Script to loaded saved model and regenerate the result for training datasets, cv and validation datasets: `load_pkl.sh`

## 2021-11-09:  Megalodon rf - downsampling -> megalodon baseline
Downsampling all the samples -> Evaluate Megalodon baseline performance on downsampled samples: `megalodon_downsampling_baseline.sh`

## 2021-11-07:  Megalodon rf - Use 5hmC:5mC:5C ratio = 1:14:14 for optimzation, evaluate megalodon baseline
1. Evauate Megalodon baseline performance on the whole datasets: `megalodon_baseline.sh`

Based on Megalondon description, I used 2 different strategies to get Megalodon per-read results:

a. Default: P(5hmC) > 0 -> site is 5hmC: `result/Megalodon.zero_cutoff.*`
b. The site will be assigned to the status based on the maximum probability, e.g.: maximum(P(5hmC), P(5mC), P(5C)) = P(5hmC) -> The site is labelled as 5mC: `result/Megalodon.max_value.*`

2. Downsampling all the samples and then build random forest model: Random search: `rf_downsampling_RandomSearch.sh`, result: `RandomSearch.noSMOTE.*`

The script is to downsampling all samples with RandomUnderSampler -> random forest with RandomSearch for best parameter

Downsampling all samples with idea ratio 0:1:2 = 14:14:1 -> Split the sample into training and testing datasets -> RandomSearch/GridSearch to find the best parameter on the training dataset -> Validate the classifer on the remaining fold -> Save the classification report and confusion matrix plotting for default parameter

3. Downsampling all the samples -> SMOTE on the training datasets -> Build random forest model with Random search: `rf_downsampling_SMOTE_RandomSearch.sh`, result: `RandomSearch.*`or Grid Search: `rf_downsampling_SMOTE_GridSearch.sh`, result: `GridSearch.*`


## 2021-11-02: Feature extraction with on CG pattern

1. Set up a new conda environment `nanomodel_python3.8` with python3.8 for deep learning model construction: 

Packages can be found in `setup_env.sh`

2. Extract CG pattern from original feature files: `/pod/2/li-lab/Ziwei/Nanopore/daily/2021-11-02/cytosine/extract_CG_feature.py`

Orignal feature patterns (C in the center, but not neighbors can be any base, not limited to CG): `/pod/2/li-lab/Ziwei/Nanopore/results/feature_Guppy5.0.11/` - `lambda_5C.csv.gz`, `lambda_5mC.csv.gz`, `T4_5hmC.csv.gz`

CG-centered feature files (C in the center with CG pattern): `/pod/2/li-lab/Ziwei/Nanopore/results/feature_Guppy5.0.11/` - `lambda_5C.CG.csv.gz`, `lambda_5mC.CG.csv.gz`, `T4_5hmC.CG.csv.gz`

## 2021-11-01: Plotting drawing

1. Install cuML for test
cuML: GPU Machine Learning Algorithms (https://github.com/rapidsai/cuml)

2. Draw tSNE-2D, tSNE-3D and UMAP for probability(5hmC, 5mC, 5C) of Megalodon 

### Problem: 

a. in tsne, The number of P(5hmC) are very limited, can't be seen on the plotting

b. Failed to draw UMAP because of out-of-memory problem

### Feedback from lab meeting (11/30/2021):

1. Draw P(5hmC) alone to get an idea about the distribution

2. The x-axis/y-axis/z-axis should not be P(5hmC)/P(5mC)/P(5C) since it is the transformed one with reduced dimension, they are no longer the original probability

3. Draw the probability directly, no need to use tSNE/UMAP since the dimensions are limited and no need to do dimension reduction


